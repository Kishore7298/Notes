# üìä Kafka End-to-End Latency with Replication

## üß™ Demo Objective
Understand how the replication factor affects end-to-end latency in a Kafka cluster.

## üß± Initial Setup ‚Äì No Replication

### Cluster Setup:
- 1 Kafka broker
- 1 topic: broker_tuning
- 3 partitions
- Replication factor = 1

### Startup Commands:
```bash
# Start Zookeeper
bin/zookeeper-server-start.sh config/zookeeper.properties

# Start broker-0
bin/kafka-server-start.sh config/server-0.properties
```

### Topic Creation:
```bash
bin/kafka-topics.sh --create \
  --topic broker_tuning \
  --partitions 3 \
  --replication-factor 1 \
  --bootstrap-server localhost:9092
```

### Verification:
```bash
bin/kafka-topics.sh --describe --topic broker_tuning
```

### Latency Test:
```bash
bin/kafka-run-class.sh kafka.tools.EndToEndLatency \
  --topic broker_tuning \
  --num-records 25000 \
  --record-size 1024 \
  --acks all
```

**Observed Latency:** ‚âà 1.63 ms

## üîÅ Updated Setup ‚Äì With Replication

### Add 2 More Brokers:
```bash
bin/kafka-server-start.sh config/server-1.properties
bin/kafka-server-start.sh config/server-2.properties
```

### Create Replication Config:
```json
{
  "partitions": [
    {"topic": "broker_tuning", "partition": 0, "replicas": [0, 1, 2]},
    {"topic": "broker_tuning", "partition": 1, "replicas": [0, 1, 2]},
    {"topic": "broker_tuning", "partition": 2, "replicas": [0, 1, 2]}
  ],
  "version": 1
}
```

### Save As:
```bash
topic_config/topic_config.json
```

### Run Partition Reassignment:
```bash
bin/kafka-reassign-partitions.sh \
  --reassignment-json-file topic_config/topic_config.json \
  --execute
```

### Verify New Replica Assignment:
```bash
bin/kafka-topics.sh --describe --topic broker_tuning
```

## ‚ö° Run Latency Test Again (With Replication)

### Same Parameters:
```bash
kafka-run-class.sh kafka.tools.EndToEndLatency \
  --topic broker_tuning \
  --num-records 25000 \
  --record-size 1024 \
  --acks all
```

**Observed Latency:** ‚âà 2.27 ms

## üß† Conclusion
- Replication factor increase ‚Üí Latency increase
  - From ~1.63 ms (replication 1)
  - To ~2.27 ms (replication 3)
- Reason: More brokers must acknowledge each message before it's considered committed due to acks=all.

[Prev](17.KafkaConsumerPoll.md) | [Index](../INDEX.md) | [Next](19.KafkaBrokerThroughputTuning.md)
