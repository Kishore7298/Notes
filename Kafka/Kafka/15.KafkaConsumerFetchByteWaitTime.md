# Tuning Kafka Consumer Fetch Bytes and Wait Time

In this part of the demo, the instructor explains how to tweak some important consumer configuration properties by editing the `consumer.properties` file directly. This is necessary because the Kafka consumer performance test script does not support overriding these properties via command-line flags.

---

## Key Properties Tweaked:

1. **fetch.min.bytes**  
   - Default: 1 byte  
   - Meaning: The minimum amount of data (in bytes) the broker must have before responding to a fetch request. By default, Kafka responds as soon as at least 1 byte is available.

2. **fetch.max.wait.ms**  
   - Default: 500 milliseconds  
   - Meaning: Maximum time the broker waits before responding to a fetch request if `fetch.min.bytes` is not met.

3. **auto.commit.interval.ms**  
   - Default: 5,000 milliseconds (5 seconds)  
   - Meaning: How often the consumer commits the offsets it has read, which affects durability.

---

## Default Behavior & Intent:

- Kafka’s default consumer configuration favors **low latency**. That means it sends data as soon as possible—when at least 1 byte is available or after 500 ms wait.
- Lower values for `fetch.min.bytes` and `fetch.max.wait.ms` lead to faster consumption but less efficient batching.
- Reducing the `auto.commit.interval.ms` (e.g., from 5 seconds to 1 second) increases commit frequency, improving durability but potentially lowering throughput because committing more often is resource-intensive.

---

## Test Results After Tweaking:

- After setting `auto.commit.interval.ms` to 1,000 ms, the throughput dropped compared to baseline:
  - Megabytes per second fell from ~25 to ~18  
  - Messages per second fell from ~25,600 to ~18,500  
  - Fetch latency increased (from 479 ms to 821 ms)  
- This reduction in throughput is attributed to the overhead of more frequent commits.

---

## Increasing Fetch Size and Wait Time:

- The instructor then increased `fetch.min.bytes` to a very large value (e.g., 500,000 bytes) and `fetch.max.wait.ms` to 2,500 ms (2.5 seconds).  
- The idea: The broker would respond only when enough data is accumulated or after a longer wait, improving batch size and throughput but increasing latency.  
- However, on a local single-broker setup, this change was not noticeably reflected in performance metrics. This is common due to limited load and environment.

---

## Additional Tuning - max.partition.fetch.bytes:

- Changed the topic to have 3 partitions to test this property.  
- Lowered `max.partition.fetch.bytes` to 1,000 bytes (from default ~1 MB). This property limits how much data the consumer can fetch in one request per partition.  
- This forces the consumer to make many more fetch requests to get all data.  
- Surprisingly, in this demo, the change did not show measurable impact on throughput or fetch times.  
- Resetting it back to default showed no difference either.  

---

## Key Takeaways:

- Kafka defaults are optimized for low latency and faster consumption with smaller fetch sizes and shorter wait times.  
- Increasing fetch size and wait time can improve throughput by batching, but may increase latency.  
- More frequent commits improve durability but reduce throughput due to overhead.  
- Some tuning effects may be subtle or not visible in a simple local setup with a single broker. They become more important and noticeable in larger, production-like environments with multiple brokers and higher load.

---


[Prev](14.KafkaConsumerPerformanceSetup.md) | [Index](../INDEX.md) | [Next](16.KafkaConsumerSessions.md)
